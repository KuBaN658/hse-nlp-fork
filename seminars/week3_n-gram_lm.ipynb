{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "k1gpzj4guo8e1riwj3om1k"
   },
   "source": [
    "### Семинар 3. Языковые модели (N-gram)\n",
    "\n",
    "В этом семинаре мы построим простейшую языковую модель генерации анекдотов. Датасет взят [отсюда](https://t.me/NeuralShit/2321)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "u8jdaiy68oib3jvr4k01",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "0c76vnyl3zui9yhtkodgrlf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/anek.txt', 'r', encoding='utf-8') as f:\n",
    "    aneki = f.read().strip().replace('<|startoftext|>', '').split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Чем х@евей квартира, тем больше требований к кандидату выдвигает арендодатель. С мужиками, кстати, это правило работает тоже.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aneki[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7u97m5s8ekl5zd5a43a1yc"
   },
   "source": [
    "### Токениация\n",
    "\n",
    "Реализуем два варианта токенизации: обычную по словам и BPE. В дальнейшем будем их сравнивать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bpe import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pct_bpe - proportion of tokens that obtained via BPE. Other are the most frequent words.\n",
    "encoder = Encoder(50000, ngram_max=6, pct_bpe=0.95)\n",
    "encoder.fit(aneki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.bpe_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('__sow', 2500),\n",
       "  ('__eow', 2501),\n",
       "  ('о', 2502),\n",
       "  ('а', 2503),\n",
       "  ('е', 2504),\n",
       "  ('и', 2505),\n",
       "  ('т', 2506),\n",
       "  ('н', 2507),\n",
       "  ('р', 2508),\n",
       "  ('с', 2509)],\n",
       " [('ньюто', 49990),\n",
       "  ('ньютон', 49991),\n",
       "  ('геи', 49992),\n",
       "  ('дилы', 49993),\n",
       "  ('одилы', 49994),\n",
       "  ('абар', 49995),\n",
       "  ('заха', 49996),\n",
       "  ('еревни', 49997),\n",
       "  ('енятьс', 49998),\n",
       "  ('изюм', 49999)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoder.bpe_vocab.items())[:10], list(encoder.bpe_vocab.items())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кто', 'сказал', ',', 'что', 'солдат', '__sow', 'мечтае', 'т', '__eow', 'стать', '__sow', 'генера', 'лом', '__eow', '?', 'солдат', '__sow', 'мечтае', 'т', '__eow', 'стать', '__sow', 'хлебо', 'резо', 'м', '__eow', '.']\n",
      "[59, 172, 2, 9, 1509, 2500, 20745, 2506, 2501, 385, 2500, 15260, 3297, 2501, 23, 1509, 2500, 20745, 2506, 2501, 385, 2500, 25012, 26588, 2441, 2501, 3]\n",
      "кто сказал , что солдат мечтает стать генералом ? солдат мечтает стать хлеборезом .\n"
     ]
    }
   ],
   "source": [
    "example = aneki[42]\n",
    "print(encoder.tokenize(example))\n",
    "print(next(encoder.transform([example])))\n",
    "print(next(encoder.inverse_transform(encoder.transform([example]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_bpe(text):\n",
    "    tokenized = encoder.tokenize(text)\n",
    "    clear_tokenized = []\n",
    "    first = False\n",
    "    saw_eow = True\n",
    "    for token in tokenized:\n",
    "        if token == '__sow':\n",
    "            saw_eow = False\n",
    "            first = True\n",
    "            continue\n",
    "        elif token == '__eow':\n",
    "            saw_eow = True\n",
    "            continue\n",
    "        else:\n",
    "            if first or saw_eow:\n",
    "                clear_tokenized.append(token)\n",
    "                first = False\n",
    "            else:\n",
    "                clear_tokenized.append('##' + token)\n",
    "    return clear_tokenized\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    reg = re.compile(r'\\w+')\n",
    "    return reg.findall(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['кто',\n",
       " 'сказал',\n",
       " ',',\n",
       " 'что',\n",
       " 'солдат',\n",
       " 'мечтае',\n",
       " '##т',\n",
       " 'стать',\n",
       " 'генера',\n",
       " '##лом',\n",
       " '?',\n",
       " 'солдат',\n",
       " 'мечтае',\n",
       " '##т',\n",
       " 'стать',\n",
       " 'хлебо',\n",
       " '##резо',\n",
       " '##м',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_bpe(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qb6h3hxmr095egzv8rlzul"
   },
   "source": [
    "### N-граммная языковая модель\n",
    "\n",
    "Языковая модель – это вероятностная модель, которая считает вероятность последовательности токенов $P(w_1, \\dots, w_T)$. Так как оценивать совместную вероятность в лоб тяжело, обычно ее разбивают на произведение условных вероятностей. \n",
    "\n",
    "$$\n",
    "P(w_1, \\dots, w_T) = P(w_1)\\prod_{i=1}^T P(w_i \\mid w_{i-1}, \\dots, w_1)\n",
    "$$ \n",
    "\n",
    "На практике такие условные вероятности сложно оценивать, когда текст очень длинный. Языковые модели лучше всего работают с небольшим контекстом. Для решения этой проблемы можно явно ограничить длину контекста, записав такое предположение\n",
    "$$\n",
    "P(w_i \\mid w_{i-1}, \\dots, w_1) \\approx P(w_i \\mid w_{i-1}, \\dots, w_{i-n+1}).\n",
    "$$\n",
    "\n",
    "Данная модель называется __n-граммной языковой моделью__, так как оценивает вероятности только n-грамм токенов. Тогда итоговая вероятность последовательности токенов записывается вот так\n",
    "\n",
    "$$\n",
    "P(w_1, \\dots, w_T) = \\prod_{i=1}^T P(w_i \\mid w_{i-1}, \\dots, w_{i-n+1}).\n",
    "$$\n",
    "\n",
    "Для начало последовательности можно добавить специальные токены `[UNK]`, чтобы в условии всегда был контекст фиксированной длины.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u68wydbiioqlp5gl96mhd"
   },
   "source": [
    "В этом семинаре мы не будем ничего учить, наша модель будет счетной. Поэтому для начала нам надо посчитать, сколько раз встречается каждая n-грамма. В начало последовательности будем добавлять  `[UNK]`, а в конец – `[EOS]`. При генерации модель будет выдавать `[EOS]`, когда настанет время остановиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "og84gjipnumsakhiiu9ap",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "UNK, EOS = \"[UNK]\", \"[EOS]\"\n",
    "\n",
    "def count_ngrams(lines, n, tokenize=tokenize):\n",
    "    \"\"\"\n",
    "    Count how many times each word occured after (n - 1) previous words\n",
    "    Input: a list of strings with space-separated tokens\n",
    "    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n",
    "\n",
    "    If the prefix is too short, it should be padded with [UNK].\n",
    "    Add [EOS] at the end of each sequence and consider it as all other token\n",
    "    \"\"\"\n",
    "    counts = defaultdict(Counter)\n",
    "\n",
    "    for line in lines:\n",
    "        tokenized = [UNK] * (n - 1) + tokenize(line) + [EOS]\n",
    "        for i in range(n - 1, len(tokenized)):\n",
    "            counts[tuple(tokenized[i-n+1:i])][tokenized[i]] += 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Когда тебе в аэропорту на ногу наезжает чужой чемодан, и вместо \"Oh, sorry\" ты слышишь \"С##бался б#я!\", значит всё - Родина.',\n",
       " 'Алкоголь не решит ваших проблем. Впрочем, как и молоко.',\n",
       " 'Настоящая невестка должна держать в страхе не только мужа, но и всех его родственников. Чтобы не мотали нервы бедной девочке!',\n",
       " 'Весна! Из-под штанин робко показываются первые голые щиколотки.',\n",
       " 'Маленьких девочек сначала кладут в постель, а потом рассказывают сказки. Большим девочкам сначала рассказывают сказки, а потом кладут в постель.',\n",
       " 'В детстве я пила квас и представляла, что это пиво. Курила соломку, ела конфеты с ликером. Я была очень дерзкой бабой.',\n",
       " 'А вы заметили, как мы взрослеем? Теперь когда мы пьём, наши бывшие нас уже не так уж и волнуют.',\n",
       " 'Если нельзя объять необъятное, можно сделать это по частям.',\n",
       " 'Ну разве может женщина принести покой и уют домашнему очагу, как это делает, например, телевизор?',\n",
       " 'Работа - это такой квест, чтобы покупать продукты.',\n",
       " 'Почему людям можно кидаться словами, а мне нельзя кинуть в них топор или кирпич?',\n",
       " 'Владимир Владимирович сходил в театр и всех переиграл.',\n",
       " '- Я конечно дико извиняюсь, но не могу не спросить. Только у меня фраза \"Лучшие жены получаются из бывших проституток\" ассоциируется с фразой: \"Лучшие кастрюли получаются из унитазов взятых в общественном сортире\"?',\n",
       " 'Во время Великого поста благочестивые попы пересаживаются из роскошных \"Кадиллаков\" и \"Майбахов\" в скромные \"Тойоты\" и \"Мерседесы\"...',\n",
       " '- Теперь, как настоящий мужчина, вы просто обязаны на мне жениться!- Сударыня, как настоящий мужчина, я уже женат!',\n",
       " 'Решающее влияние на политику оказывают не участвующие в ней.',\n",
       " 'У меня кот очень громко мяукает, так хочется, особенно ночью, поставить его на вибрацию.',\n",
       " 'Рыба ищет где поглубже, а мужик где потуже.',\n",
       " 'Почему кто-то вечно жрёт бургеры и худой как скелет, а я лишний глоток воды сделаю и все, привет ожирение.',\n",
       " 'Поспорили с женой, кто в доме главный. Она сказала, что хозяин тот, кто мусор выносит.Вот змеюка!',\n",
       " 'Последним раскрытым громким преступлением в Киеве было убийство Столыпина...',\n",
       " 'Если бесконечное количество российских футболистов запустить на бесконечное количество футбольных полей и дать им бесконечное количество времени, то один из них когда-нибудь забьёт гол.',\n",
       " 'На чемпионат мира по футболу от России нужно Юлию Самойлову отправлять, хоть какая-то надежда на победу будет.',\n",
       " 'В целях профилактики от всего весной следует есть много чеснока. От женщин, кстати, тоже помогает.',\n",
       " 'На моих глазах как-то две девушки затаскивали кавказца в машину. Они худенькие, а он здоровый такой, никак не хотел в машину лезть. Они попросили у меня помощи, сказали, что собаку надо в ветклинику отвезти.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lines = aneki[-25:]\n",
    "dummy_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellId": "xyf2he6lak9mmqarl3nck",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_counts = count_ngrams(dummy_lines, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {('[UNK]',\n",
       "              '[UNK]'): Counter({'когда': 1,\n",
       "                      'алкоголь': 1,\n",
       "                      'настоящая': 1,\n",
       "                      'весна': 1,\n",
       "                      'маленьких': 1,\n",
       "                      'в': 2,\n",
       "                      'а': 1,\n",
       "                      'если': 2,\n",
       "                      'ну': 1,\n",
       "                      'работа': 1,\n",
       "                      'почему': 2,\n",
       "                      'владимир': 1,\n",
       "                      'я': 1,\n",
       "                      'во': 1,\n",
       "                      'теперь': 1,\n",
       "                      'решающее': 1,\n",
       "                      'у': 1,\n",
       "                      'рыба': 1,\n",
       "                      'поспорили': 1,\n",
       "                      'последним': 1,\n",
       "                      'на': 2}),\n",
       "             ('[UNK]', 'когда'): Counter({'тебе': 1}),\n",
       "             ('когда', 'тебе'): Counter({'в': 1}),\n",
       "             ('тебе', 'в'): Counter({'аэропорту': 1}),\n",
       "             ('в', 'аэропорту'): Counter({'на': 1}),\n",
       "             ('аэропорту', 'на'): Counter({'ногу': 1}),\n",
       "             ('на', 'ногу'): Counter({'наезжает': 1}),\n",
       "             ('ногу', 'наезжает'): Counter({'чужой': 1}),\n",
       "             ('наезжает', 'чужой'): Counter({'чемодан': 1}),\n",
       "             ('чужой', 'чемодан'): Counter({'и': 1}),\n",
       "             ('чемодан', 'и'): Counter({'вместо': 1}),\n",
       "             ('и', 'вместо'): Counter({'oh': 1}),\n",
       "             ('вместо', 'oh'): Counter({'sorry': 1}),\n",
       "             ('oh', 'sorry'): Counter({'ты': 1}),\n",
       "             ('sorry', 'ты'): Counter({'слышишь': 1}),\n",
       "             ('ты', 'слышишь'): Counter({'с': 1}),\n",
       "             ('слышишь', 'с'): Counter({'бался': 1}),\n",
       "             ('с', 'бался'): Counter({'б': 1}),\n",
       "             ('бался', 'б'): Counter({'я': 1}),\n",
       "             ('б', 'я'): Counter({'значит': 1}),\n",
       "             ('я', 'значит'): Counter({'всё': 1}),\n",
       "             ('значит', 'всё'): Counter({'родина': 1}),\n",
       "             ('всё', 'родина'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'алкоголь'): Counter({'не': 1}),\n",
       "             ('алкоголь', 'не'): Counter({'решит': 1}),\n",
       "             ('не', 'решит'): Counter({'ваших': 1}),\n",
       "             ('решит', 'ваших'): Counter({'проблем': 1}),\n",
       "             ('ваших', 'проблем'): Counter({'впрочем': 1}),\n",
       "             ('проблем', 'впрочем'): Counter({'как': 1}),\n",
       "             ('впрочем', 'как'): Counter({'и': 1}),\n",
       "             ('как', 'и'): Counter({'молоко': 1}),\n",
       "             ('и', 'молоко'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'настоящая'): Counter({'невестка': 1}),\n",
       "             ('настоящая', 'невестка'): Counter({'должна': 1}),\n",
       "             ('невестка', 'должна'): Counter({'держать': 1}),\n",
       "             ('должна', 'держать'): Counter({'в': 1}),\n",
       "             ('держать', 'в'): Counter({'страхе': 1}),\n",
       "             ('в', 'страхе'): Counter({'не': 1}),\n",
       "             ('страхе', 'не'): Counter({'только': 1}),\n",
       "             ('не', 'только'): Counter({'мужа': 1}),\n",
       "             ('только', 'мужа'): Counter({'но': 1}),\n",
       "             ('мужа', 'но'): Counter({'и': 1}),\n",
       "             ('но', 'и'): Counter({'всех': 1}),\n",
       "             ('и', 'всех'): Counter({'его': 1, 'переиграл': 1}),\n",
       "             ('всех', 'его'): Counter({'родственников': 1}),\n",
       "             ('его', 'родственников'): Counter({'чтобы': 1}),\n",
       "             ('родственников', 'чтобы'): Counter({'не': 1}),\n",
       "             ('чтобы', 'не'): Counter({'мотали': 1}),\n",
       "             ('не', 'мотали'): Counter({'нервы': 1}),\n",
       "             ('мотали', 'нервы'): Counter({'бедной': 1}),\n",
       "             ('нервы', 'бедной'): Counter({'девочке': 1}),\n",
       "             ('бедной', 'девочке'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'весна'): Counter({'из': 1}),\n",
       "             ('весна', 'из'): Counter({'под': 1}),\n",
       "             ('из', 'под'): Counter({'штанин': 1}),\n",
       "             ('под', 'штанин'): Counter({'робко': 1}),\n",
       "             ('штанин', 'робко'): Counter({'показываются': 1}),\n",
       "             ('робко', 'показываются'): Counter({'первые': 1}),\n",
       "             ('показываются', 'первые'): Counter({'голые': 1}),\n",
       "             ('первые', 'голые'): Counter({'щиколотки': 1}),\n",
       "             ('голые', 'щиколотки'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'маленьких'): Counter({'девочек': 1}),\n",
       "             ('маленьких', 'девочек'): Counter({'сначала': 1}),\n",
       "             ('девочек', 'сначала'): Counter({'кладут': 1}),\n",
       "             ('сначала', 'кладут'): Counter({'в': 1}),\n",
       "             ('кладут', 'в'): Counter({'постель': 2}),\n",
       "             ('в', 'постель'): Counter({'а': 1, '[EOS]': 1}),\n",
       "             ('постель', 'а'): Counter({'потом': 1}),\n",
       "             ('а', 'потом'): Counter({'рассказывают': 1, 'кладут': 1}),\n",
       "             ('потом', 'рассказывают'): Counter({'сказки': 1}),\n",
       "             ('рассказывают', 'сказки'): Counter({'большим': 1, 'а': 1}),\n",
       "             ('сказки', 'большим'): Counter({'девочкам': 1}),\n",
       "             ('большим', 'девочкам'): Counter({'сначала': 1}),\n",
       "             ('девочкам', 'сначала'): Counter({'рассказывают': 1}),\n",
       "             ('сначала', 'рассказывают'): Counter({'сказки': 1}),\n",
       "             ('сказки', 'а'): Counter({'потом': 1}),\n",
       "             ('потом', 'кладут'): Counter({'в': 1}),\n",
       "             ('[UNK]', 'в'): Counter({'детстве': 1, 'целях': 1}),\n",
       "             ('в', 'детстве'): Counter({'я': 1}),\n",
       "             ('детстве', 'я'): Counter({'пила': 1}),\n",
       "             ('я', 'пила'): Counter({'квас': 1}),\n",
       "             ('пила', 'квас'): Counter({'и': 1}),\n",
       "             ('квас', 'и'): Counter({'представляла': 1}),\n",
       "             ('и', 'представляла'): Counter({'что': 1}),\n",
       "             ('представляла', 'что'): Counter({'это': 1}),\n",
       "             ('что', 'это'): Counter({'пиво': 1}),\n",
       "             ('это', 'пиво'): Counter({'курила': 1}),\n",
       "             ('пиво', 'курила'): Counter({'соломку': 1}),\n",
       "             ('курила', 'соломку'): Counter({'ела': 1}),\n",
       "             ('соломку', 'ела'): Counter({'конфеты': 1}),\n",
       "             ('ела', 'конфеты'): Counter({'с': 1}),\n",
       "             ('конфеты', 'с'): Counter({'ликером': 1}),\n",
       "             ('с', 'ликером'): Counter({'я': 1}),\n",
       "             ('ликером', 'я'): Counter({'была': 1}),\n",
       "             ('я', 'была'): Counter({'очень': 1}),\n",
       "             ('была', 'очень'): Counter({'дерзкой': 1}),\n",
       "             ('очень', 'дерзкой'): Counter({'бабой': 1}),\n",
       "             ('дерзкой', 'бабой'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'а'): Counter({'вы': 1}),\n",
       "             ('а', 'вы'): Counter({'заметили': 1}),\n",
       "             ('вы', 'заметили'): Counter({'как': 1}),\n",
       "             ('заметили', 'как'): Counter({'мы': 1}),\n",
       "             ('как', 'мы'): Counter({'взрослеем': 1}),\n",
       "             ('мы', 'взрослеем'): Counter({'теперь': 1}),\n",
       "             ('взрослеем', 'теперь'): Counter({'когда': 1}),\n",
       "             ('теперь', 'когда'): Counter({'мы': 1}),\n",
       "             ('когда', 'мы'): Counter({'пьём': 1}),\n",
       "             ('мы', 'пьём'): Counter({'наши': 1}),\n",
       "             ('пьём', 'наши'): Counter({'бывшие': 1}),\n",
       "             ('наши', 'бывшие'): Counter({'нас': 1}),\n",
       "             ('бывшие', 'нас'): Counter({'уже': 1}),\n",
       "             ('нас', 'уже'): Counter({'не': 1}),\n",
       "             ('уже', 'не'): Counter({'так': 1}),\n",
       "             ('не', 'так'): Counter({'уж': 1}),\n",
       "             ('так', 'уж'): Counter({'и': 1}),\n",
       "             ('уж', 'и'): Counter({'волнуют': 1}),\n",
       "             ('и', 'волнуют'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'если'): Counter({'нельзя': 1, 'бесконечное': 1}),\n",
       "             ('если', 'нельзя'): Counter({'объять': 1}),\n",
       "             ('нельзя', 'объять'): Counter({'необъятное': 1}),\n",
       "             ('объять', 'необъятное'): Counter({'можно': 1}),\n",
       "             ('необъятное', 'можно'): Counter({'сделать': 1}),\n",
       "             ('можно', 'сделать'): Counter({'это': 1}),\n",
       "             ('сделать', 'это'): Counter({'по': 1}),\n",
       "             ('это', 'по'): Counter({'частям': 1}),\n",
       "             ('по', 'частям'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'ну'): Counter({'разве': 1}),\n",
       "             ('ну', 'разве'): Counter({'может': 1}),\n",
       "             ('разве', 'может'): Counter({'женщина': 1}),\n",
       "             ('может', 'женщина'): Counter({'принести': 1}),\n",
       "             ('женщина', 'принести'): Counter({'покой': 1}),\n",
       "             ('принести', 'покой'): Counter({'и': 1}),\n",
       "             ('покой', 'и'): Counter({'уют': 1}),\n",
       "             ('и', 'уют'): Counter({'домашнему': 1}),\n",
       "             ('уют', 'домашнему'): Counter({'очагу': 1}),\n",
       "             ('домашнему', 'очагу'): Counter({'как': 1}),\n",
       "             ('очагу', 'как'): Counter({'это': 1}),\n",
       "             ('как', 'это'): Counter({'делает': 1}),\n",
       "             ('это', 'делает'): Counter({'например': 1}),\n",
       "             ('делает', 'например'): Counter({'телевизор': 1}),\n",
       "             ('например', 'телевизор'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'работа'): Counter({'это': 1}),\n",
       "             ('работа', 'это'): Counter({'такой': 1}),\n",
       "             ('это', 'такой'): Counter({'квест': 1}),\n",
       "             ('такой', 'квест'): Counter({'чтобы': 1}),\n",
       "             ('квест', 'чтобы'): Counter({'покупать': 1}),\n",
       "             ('чтобы', 'покупать'): Counter({'продукты': 1}),\n",
       "             ('покупать', 'продукты'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'почему'): Counter({'людям': 1, 'кто': 1}),\n",
       "             ('почему', 'людям'): Counter({'можно': 1}),\n",
       "             ('людям', 'можно'): Counter({'кидаться': 1}),\n",
       "             ('можно', 'кидаться'): Counter({'словами': 1}),\n",
       "             ('кидаться', 'словами'): Counter({'а': 1}),\n",
       "             ('словами', 'а'): Counter({'мне': 1}),\n",
       "             ('а', 'мне'): Counter({'нельзя': 1}),\n",
       "             ('мне', 'нельзя'): Counter({'кинуть': 1}),\n",
       "             ('нельзя', 'кинуть'): Counter({'в': 1}),\n",
       "             ('кинуть', 'в'): Counter({'них': 1}),\n",
       "             ('в', 'них'): Counter({'топор': 1}),\n",
       "             ('них', 'топор'): Counter({'или': 1}),\n",
       "             ('топор', 'или'): Counter({'кирпич': 1}),\n",
       "             ('или', 'кирпич'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'владимир'): Counter({'владимирович': 1}),\n",
       "             ('владимир', 'владимирович'): Counter({'сходил': 1}),\n",
       "             ('владимирович', 'сходил'): Counter({'в': 1}),\n",
       "             ('сходил', 'в'): Counter({'театр': 1}),\n",
       "             ('в', 'театр'): Counter({'и': 1}),\n",
       "             ('театр', 'и'): Counter({'всех': 1}),\n",
       "             ('всех', 'переиграл'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'я'): Counter({'конечно': 1}),\n",
       "             ('я', 'конечно'): Counter({'дико': 1}),\n",
       "             ('конечно', 'дико'): Counter({'извиняюсь': 1}),\n",
       "             ('дико', 'извиняюсь'): Counter({'но': 1}),\n",
       "             ('извиняюсь', 'но'): Counter({'не': 1}),\n",
       "             ('но', 'не'): Counter({'могу': 1}),\n",
       "             ('не', 'могу'): Counter({'не': 1}),\n",
       "             ('могу', 'не'): Counter({'спросить': 1}),\n",
       "             ('не', 'спросить'): Counter({'только': 1}),\n",
       "             ('спросить', 'только'): Counter({'у': 1}),\n",
       "             ('только', 'у'): Counter({'меня': 1}),\n",
       "             ('у', 'меня'): Counter({'фраза': 1, 'кот': 1, 'помощи': 1}),\n",
       "             ('меня', 'фраза'): Counter({'лучшие': 1}),\n",
       "             ('фраза', 'лучшие'): Counter({'жены': 1}),\n",
       "             ('лучшие', 'жены'): Counter({'получаются': 1}),\n",
       "             ('жены', 'получаются'): Counter({'из': 1}),\n",
       "             ('получаются', 'из'): Counter({'бывших': 1, 'унитазов': 1}),\n",
       "             ('из', 'бывших'): Counter({'проституток': 1}),\n",
       "             ('бывших', 'проституток'): Counter({'ассоциируется': 1}),\n",
       "             ('проституток', 'ассоциируется'): Counter({'с': 1}),\n",
       "             ('ассоциируется', 'с'): Counter({'фразой': 1}),\n",
       "             ('с', 'фразой'): Counter({'лучшие': 1}),\n",
       "             ('фразой', 'лучшие'): Counter({'кастрюли': 1}),\n",
       "             ('лучшие', 'кастрюли'): Counter({'получаются': 1}),\n",
       "             ('кастрюли', 'получаются'): Counter({'из': 1}),\n",
       "             ('из', 'унитазов'): Counter({'взятых': 1}),\n",
       "             ('унитазов', 'взятых'): Counter({'в': 1}),\n",
       "             ('взятых', 'в'): Counter({'общественном': 1}),\n",
       "             ('в', 'общественном'): Counter({'сортире': 1}),\n",
       "             ('общественном', 'сортире'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'во'): Counter({'время': 1}),\n",
       "             ('во', 'время'): Counter({'великого': 1}),\n",
       "             ('время', 'великого'): Counter({'поста': 1}),\n",
       "             ('великого', 'поста'): Counter({'благочестивые': 1}),\n",
       "             ('поста', 'благочестивые'): Counter({'попы': 1}),\n",
       "             ('благочестивые', 'попы'): Counter({'пересаживаются': 1}),\n",
       "             ('попы', 'пересаживаются'): Counter({'из': 1}),\n",
       "             ('пересаживаются', 'из'): Counter({'роскошных': 1}),\n",
       "             ('из', 'роскошных'): Counter({'кадиллаков': 1}),\n",
       "             ('роскошных', 'кадиллаков'): Counter({'и': 1}),\n",
       "             ('кадиллаков', 'и'): Counter({'майбахов': 1}),\n",
       "             ('и', 'майбахов'): Counter({'в': 1}),\n",
       "             ('майбахов', 'в'): Counter({'скромные': 1}),\n",
       "             ('в', 'скромные'): Counter({'тойоты': 1}),\n",
       "             ('скромные', 'тойоты'): Counter({'и': 1}),\n",
       "             ('тойоты', 'и'): Counter({'мерседесы': 1}),\n",
       "             ('и', 'мерседесы'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'теперь'): Counter({'как': 1}),\n",
       "             ('теперь', 'как'): Counter({'настоящий': 1}),\n",
       "             ('как', 'настоящий'): Counter({'мужчина': 2}),\n",
       "             ('настоящий', 'мужчина'): Counter({'вы': 1, 'я': 1}),\n",
       "             ('мужчина', 'вы'): Counter({'просто': 1}),\n",
       "             ('вы', 'просто'): Counter({'обязаны': 1}),\n",
       "             ('просто', 'обязаны'): Counter({'на': 1}),\n",
       "             ('обязаны', 'на'): Counter({'мне': 1}),\n",
       "             ('на', 'мне'): Counter({'жениться': 1}),\n",
       "             ('мне', 'жениться'): Counter({'сударыня': 1}),\n",
       "             ('жениться', 'сударыня'): Counter({'как': 1}),\n",
       "             ('сударыня', 'как'): Counter({'настоящий': 1}),\n",
       "             ('мужчина', 'я'): Counter({'уже': 1}),\n",
       "             ('я', 'уже'): Counter({'женат': 1}),\n",
       "             ('уже', 'женат'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'решающее'): Counter({'влияние': 1}),\n",
       "             ('решающее', 'влияние'): Counter({'на': 1}),\n",
       "             ('влияние', 'на'): Counter({'политику': 1}),\n",
       "             ('на', 'политику'): Counter({'оказывают': 1}),\n",
       "             ('политику', 'оказывают'): Counter({'не': 1}),\n",
       "             ('оказывают', 'не'): Counter({'участвующие': 1}),\n",
       "             ('не', 'участвующие'): Counter({'в': 1}),\n",
       "             ('участвующие', 'в'): Counter({'ней': 1}),\n",
       "             ('в', 'ней'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'у'): Counter({'меня': 1}),\n",
       "             ('меня', 'кот'): Counter({'очень': 1}),\n",
       "             ('кот', 'очень'): Counter({'громко': 1}),\n",
       "             ('очень', 'громко'): Counter({'мяукает': 1}),\n",
       "             ('громко', 'мяукает'): Counter({'так': 1}),\n",
       "             ('мяукает', 'так'): Counter({'хочется': 1}),\n",
       "             ('так', 'хочется'): Counter({'особенно': 1}),\n",
       "             ('хочется', 'особенно'): Counter({'ночью': 1}),\n",
       "             ('особенно', 'ночью'): Counter({'поставить': 1}),\n",
       "             ('ночью', 'поставить'): Counter({'его': 1}),\n",
       "             ('поставить', 'его'): Counter({'на': 1}),\n",
       "             ('его', 'на'): Counter({'вибрацию': 1}),\n",
       "             ('на', 'вибрацию'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'рыба'): Counter({'ищет': 1}),\n",
       "             ('рыба', 'ищет'): Counter({'где': 1}),\n",
       "             ('ищет', 'где'): Counter({'поглубже': 1}),\n",
       "             ('где', 'поглубже'): Counter({'а': 1}),\n",
       "             ('поглубже', 'а'): Counter({'мужик': 1}),\n",
       "             ('а', 'мужик'): Counter({'где': 1}),\n",
       "             ('мужик', 'где'): Counter({'потуже': 1}),\n",
       "             ('где', 'потуже'): Counter({'[EOS]': 1}),\n",
       "             ('почему', 'кто'): Counter({'то': 1}),\n",
       "             ('кто', 'то'): Counter({'вечно': 1}),\n",
       "             ('то', 'вечно'): Counter({'жрёт': 1}),\n",
       "             ('вечно', 'жрёт'): Counter({'бургеры': 1}),\n",
       "             ('жрёт', 'бургеры'): Counter({'и': 1}),\n",
       "             ('бургеры', 'и'): Counter({'худой': 1}),\n",
       "             ('и', 'худой'): Counter({'как': 1}),\n",
       "             ('худой', 'как'): Counter({'скелет': 1}),\n",
       "             ('как', 'скелет'): Counter({'а': 1}),\n",
       "             ('скелет', 'а'): Counter({'я': 1}),\n",
       "             ('а', 'я'): Counter({'лишний': 1}),\n",
       "             ('я', 'лишний'): Counter({'глоток': 1}),\n",
       "             ('лишний', 'глоток'): Counter({'воды': 1}),\n",
       "             ('глоток', 'воды'): Counter({'сделаю': 1}),\n",
       "             ('воды', 'сделаю'): Counter({'и': 1}),\n",
       "             ('сделаю', 'и'): Counter({'все': 1}),\n",
       "             ('и', 'все'): Counter({'привет': 1}),\n",
       "             ('все', 'привет'): Counter({'ожирение': 1}),\n",
       "             ('привет', 'ожирение'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'поспорили'): Counter({'с': 1}),\n",
       "             ('поспорили', 'с'): Counter({'женой': 1}),\n",
       "             ('с', 'женой'): Counter({'кто': 1}),\n",
       "             ('женой', 'кто'): Counter({'в': 1}),\n",
       "             ('кто', 'в'): Counter({'доме': 1}),\n",
       "             ('в', 'доме'): Counter({'главный': 1}),\n",
       "             ('доме', 'главный'): Counter({'она': 1}),\n",
       "             ('главный', 'она'): Counter({'сказала': 1}),\n",
       "             ('она', 'сказала'): Counter({'что': 1}),\n",
       "             ('сказала', 'что'): Counter({'хозяин': 1}),\n",
       "             ('что', 'хозяин'): Counter({'тот': 1}),\n",
       "             ('хозяин', 'тот'): Counter({'кто': 1}),\n",
       "             ('тот', 'кто'): Counter({'мусор': 1}),\n",
       "             ('кто', 'мусор'): Counter({'выносит': 1}),\n",
       "             ('мусор', 'выносит'): Counter({'вот': 1}),\n",
       "             ('выносит', 'вот'): Counter({'змеюка': 1}),\n",
       "             ('вот', 'змеюка'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'последним'): Counter({'раскрытым': 1}),\n",
       "             ('последним', 'раскрытым'): Counter({'громким': 1}),\n",
       "             ('раскрытым', 'громким'): Counter({'преступлением': 1}),\n",
       "             ('громким', 'преступлением'): Counter({'в': 1}),\n",
       "             ('преступлением', 'в'): Counter({'киеве': 1}),\n",
       "             ('в', 'киеве'): Counter({'было': 1}),\n",
       "             ('киеве', 'было'): Counter({'убийство': 1}),\n",
       "             ('было', 'убийство'): Counter({'столыпина': 1}),\n",
       "             ('убийство', 'столыпина'): Counter({'[EOS]': 1}),\n",
       "             ('если', 'бесконечное'): Counter({'количество': 1}),\n",
       "             ('бесконечное',\n",
       "              'количество'): Counter({'российских': 1,\n",
       "                      'футбольных': 1,\n",
       "                      'времени': 1}),\n",
       "             ('количество', 'российских'): Counter({'футболистов': 1}),\n",
       "             ('российских', 'футболистов'): Counter({'запустить': 1}),\n",
       "             ('футболистов', 'запустить'): Counter({'на': 1}),\n",
       "             ('запустить', 'на'): Counter({'бесконечное': 1}),\n",
       "             ('на', 'бесконечное'): Counter({'количество': 1}),\n",
       "             ('количество', 'футбольных'): Counter({'полей': 1}),\n",
       "             ('футбольных', 'полей'): Counter({'и': 1}),\n",
       "             ('полей', 'и'): Counter({'дать': 1}),\n",
       "             ('и', 'дать'): Counter({'им': 1}),\n",
       "             ('дать', 'им'): Counter({'бесконечное': 1}),\n",
       "             ('им', 'бесконечное'): Counter({'количество': 1}),\n",
       "             ('количество', 'времени'): Counter({'то': 1}),\n",
       "             ('времени', 'то'): Counter({'один': 1}),\n",
       "             ('то', 'один'): Counter({'из': 1}),\n",
       "             ('один', 'из'): Counter({'них': 1}),\n",
       "             ('из', 'них'): Counter({'когда': 1}),\n",
       "             ('них', 'когда'): Counter({'нибудь': 1}),\n",
       "             ('когда', 'нибудь'): Counter({'забьёт': 1}),\n",
       "             ('нибудь', 'забьёт'): Counter({'гол': 1}),\n",
       "             ('забьёт', 'гол'): Counter({'[EOS]': 1}),\n",
       "             ('[UNK]', 'на'): Counter({'чемпионат': 1, 'моих': 1}),\n",
       "             ('на', 'чемпионат'): Counter({'мира': 1}),\n",
       "             ('чемпионат', 'мира'): Counter({'по': 1}),\n",
       "             ('мира', 'по'): Counter({'футболу': 1}),\n",
       "             ('по', 'футболу'): Counter({'от': 1}),\n",
       "             ('футболу', 'от'): Counter({'россии': 1}),\n",
       "             ('от', 'россии'): Counter({'нужно': 1}),\n",
       "             ('россии', 'нужно'): Counter({'юлию': 1}),\n",
       "             ('нужно', 'юлию'): Counter({'самойлову': 1}),\n",
       "             ('юлию', 'самойлову'): Counter({'отправлять': 1}),\n",
       "             ('самойлову', 'отправлять'): Counter({'хоть': 1}),\n",
       "             ('отправлять', 'хоть'): Counter({'какая': 1}),\n",
       "             ('хоть', 'какая'): Counter({'то': 1}),\n",
       "             ('какая', 'то'): Counter({'надежда': 1}),\n",
       "             ('то', 'надежда'): Counter({'на': 1}),\n",
       "             ('надежда', 'на'): Counter({'победу': 1}),\n",
       "             ('на', 'победу'): Counter({'будет': 1}),\n",
       "             ('победу', 'будет'): Counter({'[EOS]': 1}),\n",
       "             ('в', 'целях'): Counter({'профилактики': 1}),\n",
       "             ('целях', 'профилактики'): Counter({'от': 1}),\n",
       "             ('профилактики', 'от'): Counter({'всего': 1}),\n",
       "             ('от', 'всего'): Counter({'весной': 1}),\n",
       "             ('всего', 'весной'): Counter({'следует': 1}),\n",
       "             ('весной', 'следует'): Counter({'есть': 1}),\n",
       "             ('следует', 'есть'): Counter({'много': 1}),\n",
       "             ('есть', 'много'): Counter({'чеснока': 1}),\n",
       "             ('много', 'чеснока'): Counter({'от': 1}),\n",
       "             ('чеснока', 'от'): Counter({'женщин': 1}),\n",
       "             ('от', 'женщин'): Counter({'кстати': 1}),\n",
       "             ('женщин', 'кстати'): Counter({'тоже': 1}),\n",
       "             ('кстати', 'тоже'): Counter({'помогает': 1}),\n",
       "             ('тоже', 'помогает'): Counter({'[EOS]': 1}),\n",
       "             ('на', 'моих'): Counter({'глазах': 1}),\n",
       "             ('моих', 'глазах'): Counter({'как': 1}),\n",
       "             ('глазах', 'как'): Counter({'то': 1}),\n",
       "             ('как', 'то'): Counter({'две': 1}),\n",
       "             ('то', 'две'): Counter({'девушки': 1}),\n",
       "             ('две', 'девушки'): Counter({'затаскивали': 1}),\n",
       "             ('девушки', 'затаскивали'): Counter({'кавказца': 1}),\n",
       "             ('затаскивали', 'кавказца'): Counter({'в': 1}),\n",
       "             ('кавказца', 'в'): Counter({'машину': 1}),\n",
       "             ('в', 'машину'): Counter({'они': 1, 'лезть': 1}),\n",
       "             ('машину', 'они'): Counter({'худенькие': 1}),\n",
       "             ('они', 'худенькие'): Counter({'а': 1}),\n",
       "             ('худенькие', 'а'): Counter({'он': 1}),\n",
       "             ('а', 'он'): Counter({'здоровый': 1}),\n",
       "             ('он', 'здоровый'): Counter({'такой': 1}),\n",
       "             ('здоровый', 'такой'): Counter({'никак': 1}),\n",
       "             ('такой', 'никак'): Counter({'не': 1}),\n",
       "             ('никак', 'не'): Counter({'хотел': 1}),\n",
       "             ('не', 'хотел'): Counter({'в': 1}),\n",
       "             ('хотел', 'в'): Counter({'машину': 1}),\n",
       "             ('машину', 'лезть'): Counter({'они': 1}),\n",
       "             ('лезть', 'они'): Counter({'попросили': 1}),\n",
       "             ('они', 'попросили'): Counter({'у': 1}),\n",
       "             ('попросили', 'у'): Counter({'меня': 1}),\n",
       "             ('меня', 'помощи'): Counter({'сказали': 1}),\n",
       "             ('помощи', 'сказали'): Counter({'что': 1}),\n",
       "             ('сказали', 'что'): Counter({'собаку': 1}),\n",
       "             ('что', 'собаку'): Counter({'надо': 1}),\n",
       "             ('собаку', 'надо'): Counter({'в': 1}),\n",
       "             ('надо', 'в'): Counter({'ветклинику': 1}),\n",
       "             ('в', 'ветклинику'): Counter({'отвезти': 1}),\n",
       "             ('ветклинику', 'отвезти'): Counter({'[EOS]': 1})})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'в': 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_counts[('громким', 'преступлением')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'когда': 1,\n",
       "         'алкоголь': 1,\n",
       "         'настоящая': 1,\n",
       "         'весна': 1,\n",
       "         'маленьких': 1,\n",
       "         'в': 2,\n",
       "         'а': 1,\n",
       "         'если': 2,\n",
       "         'ну': 1,\n",
       "         'работа': 1,\n",
       "         'почему': 2,\n",
       "         'владимир': 1,\n",
       "         'я': 1,\n",
       "         'во': 1,\n",
       "         'теперь': 1,\n",
       "         'решающее': 1,\n",
       "         'у': 1,\n",
       "         'рыба': 1,\n",
       "         'поспорили': 1,\n",
       "         'последним': 1,\n",
       "         'на': 2})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_counts[(UNK, UNK)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4j620npeqvj0k8ak8xqx8xk"
   },
   "source": [
    "Теперь мы можем оценить вероятности, используя посчитанные n-граммы.\n",
    "\n",
    "$$ P(w_i | prefix) = \\frac{Count(prefix, w_i)}{\\sum_{w \\in V} Count(prefix, w)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModel:\n",
    "    def __init__(self, corpus, n=3, tokenize=tokenize):\n",
    "\n",
    "        counts = count_ngrams(corpus, n, tokenize=tokenize)\n",
    "        self.n = n\n",
    "\n",
    "        self.probs = defaultdict(Counter)\n",
    "\n",
    "        # calculate the probabilities using the formula above\n",
    "        for prefix, token_count in counts.items():\n",
    "            token_sum = sum(token_count.values())\n",
    "            for token, count in token_count.items():\n",
    "                self.probs[prefix][token] = count / token_sum\n",
    "        \n",
    "    def process_prefix(self, prefix):\n",
    "        if self.n == 1:\n",
    "            prefix = []\n",
    "        else:\n",
    "            prefix = prefix[-(self.n - 1):]\n",
    "            prefix = [UNK] * (self.n - 1 - len(prefix)) + prefix\n",
    "            \n",
    "        return prefix\n",
    "\n",
    "    def get_tokens_and_probs(self, prefix):\n",
    "        prefix = self.process_prefix(prefix)\n",
    "\n",
    "        possible_tokens = self.probs[tuple(prefix)]\n",
    "\n",
    "        tokens = list(possible_tokens.keys())\n",
    "        probs = list(possible_tokens.values())\n",
    "\n",
    "        return tokens, probs\n",
    "    \n",
    "    def get_token_prob(self, token, prefix):\n",
    "        prefix = self.process_prefix(prefix)\n",
    "\n",
    "        prob = self.probs[tuple(prefix)].get(token, 0)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oh8r9a41kuk4r51wra9"
   },
   "source": [
    "Наконец, мы можем использовать полученную модель для генерации анекдотов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cellId": "f17xoejjppmooo2nopw4xo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(aneki, n=10, tokenize=tokenize_bpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2kd9glwnkr470qc4bt7f1e"
   },
   "source": [
    "Процесс генерации всегда авторегрессионный. Это значит, что выход модели на предыдущем шаге поступает на вход следующего. Таким образом можно бесконечно генерировать текст (ну или до тех пор, пока модель не выдаст [EOS]).\n",
    "\n",
    "Для выбора одного токена из всех возможных вариантов существует огромное количество техник. Например, можно брать самый вероятный или семплировать токен в соответствии с вероятностями. Более подробно обсудим это на 4 семинаре. Мы остановимся на втором подходе, чтобы каждый раз получались разные тексты.\n",
    "\n",
    "$$w_{next} \\sim \\frac{P(w_{next} | prefix)}{\\sum_{w} P(w | prefix)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cellId": "sgbatlm9vzb4z889fho7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_next_token(lm, prefix):\n",
    "    tokens, probs = lm.get_tokens_and_probs(prefix)\n",
    "\n",
    "    next_token = np.random.choice(tokens, p=probs)\n",
    "    return next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cellId": "1nnnycga61rijt6nd8zai",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как же я сильно скучаю по времени плен ##очных фотоап ##парат ##ов , когда люди дорож ##или каждым кадро ##м , а не снимал ##и всякую х @ рн ##ю . [EOS]\n"
     ]
    }
   ],
   "source": [
    "prefix = tokenize('как')\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += [get_next_token(lm, prefix)]\n",
    "    if prefix[-1] == EOS or len(lm.get_tokens_and_probs(prefix)[0]) == 0:\n",
    "        break\n",
    "\n",
    "print(' '.join(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3gdmey7g8at5n5c5x4gayh"
   },
   "source": [
    "### Оценка качества языковой модели: перплексия\n",
    "\n",
    "Перплексия оценивает то, насколько хорошо модель предсказывает распределение данных. Она считатся по данной формуле:\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1 \\dots w_T) = PPL(w_1, \\dots, w_T)^{-\\frac{1}{T}} = \\left( \\prod_i P(w_i \\mid w_{i-1}, \\dots, w_{i - n + 1})\\right)^{-\\frac{1}{T}},\n",
    "$$\n",
    "\n",
    "Можно заметить, что это в точности экспонента кросс-энтропии. Поэтому, чем меньше перплексия, тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cellId": "5hp010xyzzb4vqewo1bhny",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perplexity(lm, lines, min_prob=10 ** -50., tokenize=tokenize):\n",
    "    \"\"\"\n",
    "    :param min_prob: if P(w | ...) is smaller than min_prop, set it to min_prob.\n",
    "    :returns: mean perplexity over the whole corpus\n",
    "    \"\"\"\n",
    "\n",
    "    ppls = []\n",
    "    for line in tqdm(lines):\n",
    "        tokenized = tokenize(line)\n",
    "        log_ppl = 0\n",
    "        for i in range(len(tokenized)):\n",
    "            log_ppl += np.log(max(\n",
    "                min_prob,\n",
    "                lm.get_token_prob(tokenized[i], tokenized[:i])\n",
    "            ))\n",
    "        ppls.append(np.exp(-log_ppl / len(tokenized)))\n",
    "\n",
    "    return np.mean(ppls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3bcbf83d9245b8a1daaee0ca3059f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecd787a83a14e4e9a4ff9a9d0bb791f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962d74ce6da94ef5a06a7b580de257d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexities: ppx1=250.648 ppx3=1.314 ppx10=1.277\n"
     ]
    }
   ],
   "source": [
    "lm1 = NGramLanguageModel(dummy_lines, n=1)\n",
    "lm3 = NGramLanguageModel(dummy_lines, n=3)\n",
    "lm10 = NGramLanguageModel(dummy_lines, n=10)\n",
    "\n",
    "ppx1 = perplexity(lm1, dummy_lines)\n",
    "ppx3 = perplexity(lm3, dummy_lines)\n",
    "ppx10 = perplexity(lm10, dummy_lines)\n",
    "\n",
    "print(\"Perplexities: ppx1=%.3f ppx3=%.3f ppx10=%.3f\" % (ppx1, ppx3, ppx10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ypc4lks4vs1li908fqi8"
   },
   "source": [
    "Теперь мы можем посчитать перплексию нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cellId": "tjnehsem2lmijkg2lto4w",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b08223a9c245f0a3a77aa87b1c3ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 12887014247997405467423213088777838380250562560.00000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cd3ad5c2a248fc84658d97c92d998d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 2, Perplexity = 460881476685444201036843739570228114189619036160.00000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17783cd04258499ea7a80f518c973312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 3, Perplexity = 3010794325323826519754827834236485472713017655296.00000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, test_lines = train_test_split(aneki, test_size=0.25, random_state=42)\n",
    "\n",
    "for n in (1, 2, 3):\n",
    "    lm = NGramLanguageModel(train_lines, n=n)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oopn2o57wxm9vbxzycytce"
   },
   "source": [
    "### Сглаживание вероятностей\n",
    "\n",
    "Проблема заключается в следующем. Каждый раз, когда модель встречает в тестовом корпусе n-грамму, которой не было в тренировочном, она присваивает ей нулевую вероятность. Соответствено, все произведение зануляется, независимо от того, как выглядит остальной текст.\n",
    "\n",
    "Один из способов обойти это – добавить сглаживание вероятностей ([сглаживание Лапласа](https://en.wikipedia.org/wiki/Additive_smoothing)). Сделаем вид, что мы видели каждую n-грамму хотя бы один раз. При наличии достаточно большого корпуса, это почти не поменяет распределения вероятностей, но зато позволит нам не взрывать перплексию.\n",
    "\n",
    "$$ P(w_t \\mid prefix) = \\frac{Count(prefix, w_t) + \\delta}{\\sum_{w \\in V} \\big(Count(prefix, w) + \\delta\\big)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cellId": "ioh26rlov6g8l2ssj1c8pm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(NGramLanguageModel):\n",
    "    def __init__(self, corpus, n, delta=1.0, tokenize=tokenize):\n",
    "\n",
    "        counts = count_ngrams(corpus, n, tokenize=tokenize)\n",
    "        self.n = n\n",
    "        self.vocab = set()\n",
    "        for token_count in counts.values():\n",
    "            self.vocab |= set(token_count.keys())\n",
    "\n",
    "        self.probs = defaultdict(Counter)\n",
    "        for prefix, token_count in counts.items():\n",
    "            total = sum(token_count.values()) + delta * len(self.vocab)\n",
    "            for token, count in token_count.items():\n",
    "                self.probs[prefix][token] = (count + delta) / total\n",
    "\n",
    "    def get_tokens_and_probs(self, prefix):\n",
    "        # we want to spread some propability among all tokens\n",
    "        \n",
    "        tokens, probs = super().get_possible_next_tokens(prefix)\n",
    "        \n",
    "        left_prob = 1.0 - sum(probs)\n",
    "        unseen_prob = left_prob / max(1, len(self.vocab) - len(tokens))\n",
    "        \n",
    "        unseen_tokens = self.vocab - set(tokens)\n",
    "\n",
    "        return tokens + list(unseen_tokens), probs + [unseen_prob] * len(unseen_tokens)\n",
    "\n",
    "    def get_token_prob(self, token, prefix):\n",
    "        prob = super().get_token_prob(token, prefix)\n",
    "        if prob > 0:\n",
    "            return prob\n",
    "\n",
    "        tokens, probs = super().get_tokens_and_probs(prefix)\n",
    "\n",
    "        left_prob = max(1e-8, 1.0 - sum(probs))\n",
    "        unseen_prob = left_prob / max(1, len(self.vocab) - len(tokens))\n",
    "\n",
    "        return unseen_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cellId": "3xvxkdxcmfqucruyt66mdc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = LaplaceLanguageModel(dummy_lines, n=n)\n",
    "    assert sum(([dummy_lm.get_token_prob(w_i, ['l']) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f6aca2ee70487b91738ae1fa128c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 39955.87579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f1b2c766b04578b9baf7d00b83d50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 2, Perplexity = 30058.30273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac1df60617a4324ac7836e3ad6df307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 3, Perplexity = 70786.18871\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = LaplaceLanguageModel(train_lines, n=n, delta=1)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fccfbdaf7740be9ef30079256f4d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 2695.94599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13557f0d8b624d00bd962a3138bbe9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 2, Perplexity = 3860.07277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d08715f16b249a5a59fad9838b0b65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 3, Perplexity = 15598.23201\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = LaplaceLanguageModel(train_lines, n=n, delta=1, tokenize=tokenize_bpe)\n",
    "    ppx = perplexity(lm, test_lines, tokenize=tokenize_bpe)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "notebookId": "53997d2d-afb8-4477-8874-b6d46299f06c",
  "notebookPath": "seminar.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
